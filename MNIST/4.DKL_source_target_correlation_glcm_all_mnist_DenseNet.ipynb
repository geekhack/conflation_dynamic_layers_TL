{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import json\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "from numpy import expand_dims, array, exp, max\n",
    "import scipy\n",
    "from scipy.special import rel_entr\n",
    "import csv\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to suppress division errors\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "new_final_source_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening final JSON files\n",
    "energy_source_data = open('../../../paper3/files/glcm/source_domain_data_new_energy_glcm.json')\n",
    "correlation_source_data = open('../../../paper3/files/glcm/source_domain_data_new_correlation_glcm.json')\n",
    "homogeneity_source_data = open('../../../paper3/files/glcm/source_domain_data_new_homogeneity_glcm.json')\n",
    "\n",
    "#for target data\n",
    "energy_target_data = open('DenseNet169/glcm/mnist_domain_data_new_energy_glcm.json')\n",
    "correlation_target_data = open('DenseNet169/glcm/mnist_domain_data_new_correlation_glcm.json')\n",
    "homogeneity_target_data = open('DenseNet169/glcm/mnist_domain_data_new_homogeneity_glcm.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns JSON object\n",
    "energy_source_data_d = json.load(energy_source_data)\n",
    "correlation_source_data_d = json.load(correlation_source_data)\n",
    "homogeneity_source_data_d = json.load(homogeneity_source_data)\n",
    "\n",
    "energy_target_data_d = json.load(energy_target_data)\n",
    "correlation_target_data_d = json.load(correlation_target_data)\n",
    "homogeneity_target_data_d = json.load(homogeneity_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kdl dictionary\n",
    "kdl_dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(p, q):\n",
    "    a = []\n",
    "    b = []\n",
    "    for k in p:\n",
    "        a.append(Decimal(k))\n",
    "\n",
    "    for l in q:\n",
    "        b.append(Decimal(l))\n",
    "\n",
    "    a = np.asarray(a, dtype=np.float64)\n",
    "    b = np.asarray(b, dtype=np.float64)\n",
    "\n",
    "    return np.sum(np.where(((a != 0) & (b != 0)), a * np.log(a / b), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softMax(temperature, features_list):\n",
    "    feat_list = [x / temperature for x in features_list]\n",
    "    feature_list = exp(feat_list - max(feat_list))\n",
    "    return feature_list / feature_list.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for the energy target image\n",
    "energy_target_data_array = []\n",
    "for p in range(0, len(energy_target_data_d['target_images'])):\n",
    "    for i, j in energy_target_data_d['target_images'][p].items():\n",
    "        energy_target_data_array.append((i,np.array(j)))\n",
    "energy_target_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for the correlation target image\n",
    "correlation_target_data_array = []\n",
    "for p in range(0, len(correlation_target_data_d['target_images'])):\n",
    "    for i, j in correlation_target_data_d['target_images'][p].items():\n",
    "        correlation_target_data_array.append((i,np.array(j)))\n",
    "correlation_target_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for the homogeneity target image\n",
    "homogeneity_target_data_array = []\n",
    "for p in range(0, len(homogeneity_target_data_d['target_images'])):\n",
    "    for i, j in homogeneity_target_data_d['target_images'][p].items():\n",
    "        homogeneity_target_data_array.append((i,np.array(j)))\n",
    "homogeneity_target_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(homogeneity_target_data_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###energy comparison code\n",
    "energy_All_Images = []\n",
    "energy_average_dkl = []\n",
    "\n",
    "for x in energy_target_data_array[:4500]:\n",
    "#for x in target_data_array:\n",
    "    t_images_btween_0_05 = []\n",
    "    t_images_btween_05_1 = []\n",
    "    t_images_btween_1_2 = []\n",
    "    t_images_grt_2_5 = []\n",
    "    t_images_grt_5_10 = []\n",
    "    t_images_grt_10 = []\n",
    "    \n",
    "    image_name_class =  x[0].split('_/') #name[0]; class[1]\n",
    "    compare_min_max = []\n",
    "    \n",
    "    \n",
    "            \n",
    "    # get the data for the source images\n",
    "    for m in range(0, len(energy_source_data_d['source_images'])):\n",
    "        #print(\"source\",source_data_d['source_images'][m][0])\n",
    "        for k, v in energy_source_data_d['source_images'][m].items():\n",
    "            # compare the value of v with that of the target image\n",
    "            # if 'caterpillar' in k.lower():\n",
    "            # remove the zeros from the list\n",
    "            new_v = np.array(v).flatten()\n",
    "            #get the top items in x\n",
    "            items = np.sort(x[1])\n",
    "            item_size = items[-len(new_v):]\n",
    "            new_x = item_size.flatten()\n",
    "            \n",
    "            new_d = softMax(0.5, new_x)     \n",
    "            new_y = softMax(0.5, new_v)\n",
    "            \n",
    "            kdl = rel_entr( new_x, new_v, out=None)\n",
    "            \n",
    "            compare_min_max.append((image_name_class[0],image_name_class[1],k, max(kdl)))\n",
    "           \n",
    "    energy_All_Images.append(compare_min_max)\n",
    "energy_source_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###correlation comparison code\n",
    "correlation_All_Images = []\n",
    "correlation_average_dkl = []\n",
    "\n",
    "for x in correlation_target_data_array[:4500]:\n",
    "#for x in target_data_array:\n",
    "    t_images_btween_0_05 = []\n",
    "    t_images_btween_05_1 = []\n",
    "    t_images_btween_1_2 = []\n",
    "    t_images_grt_2_5 = []\n",
    "    t_images_grt_5_10 = []\n",
    "    t_images_grt_10 = []\n",
    "    \n",
    "    image_name_class =  x[0].split('_/') #name[0]; class[1]\n",
    "    compare_min_max = []\n",
    "    \n",
    "    \n",
    "            \n",
    "    # get the data for the source images\n",
    "    for m in range(0, len(correlation_source_data_d['source_images'])):\n",
    "        #print(\"source\",source_data_d['source_images'][m][0])\n",
    "        for k, v in correlation_source_data_d['source_images'][m].items():\n",
    "            # compare the value of v with that of the target image\n",
    "            # if 'caterpillar' in k.lower():\n",
    "            # remove the zeros from the list\n",
    "            new_v = np.array(v).flatten()\n",
    "            #get the top items in x\n",
    "            items = np.sort(x[1])\n",
    "            item_size = items[-len(new_v):]\n",
    "            new_x = item_size.flatten()\n",
    "            \n",
    "            new_d = softMax(0.5, new_x)     \n",
    "            new_y = softMax(0.5, new_v)\n",
    "            \n",
    "            kdl = rel_entr( new_x, new_v, out=None)\n",
    "            \n",
    "            compare_min_max.append((image_name_class[0],image_name_class[1],k, max(kdl)))\n",
    "            \n",
    "    #####All_Images.append((image_name_class[0],image_name_class[1],list((len(t_images_btween_0_05),len(t_images_btween_05_1),len(t_images_btween_1_2),len(t_images_grt_2_5), len(t_images_grt_5_10),len(t_images_grt_10)))))\n",
    "    correlation_All_Images.append(compare_min_max)\n",
    "correlation_source_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###homogeneity comparison code\n",
    "homogeneity_All_Images = []\n",
    "homogeneity_average_dkl = []\n",
    "\n",
    "for x in homogeneity_target_data_array[:4500]:\n",
    "#for x in target_data_array:\n",
    "    t_images_btween_0_05 = []\n",
    "    t_images_btween_05_1 = []\n",
    "    t_images_btween_1_2 = []\n",
    "    t_images_grt_2_5 = []\n",
    "    t_images_grt_5_10 = []\n",
    "    t_images_grt_10 = []\n",
    "    \n",
    "    image_name_class =  x[0].split('_/') #name[0]; class[1]\n",
    "    compare_min_max = []\n",
    "    \n",
    "    \n",
    "            \n",
    "    # get the data for the source images\n",
    "    for m in range(0, len(homogeneity_source_data_d['source_images'])):\n",
    "        #print(\"source\",source_data_d['source_images'][m][0])\n",
    "        for k, v in homogeneity_source_data_d['source_images'][m].items():\n",
    "            # compare the value of v with that of the target image\n",
    "            # if 'caterpillar' in k.lower():\n",
    "            # remove the zeros from the list\n",
    "            new_v = np.array(v).flatten()\n",
    "            #get the top items in x\n",
    "            items = np.sort(x[1])\n",
    "            item_size = items[-len(new_v):]\n",
    "            new_x = item_size.flatten()\n",
    "            \n",
    "            new_d = softMax(0.5, new_x)     \n",
    "            new_y = softMax(0.5, new_v)\n",
    "            \n",
    "            kdl = rel_entr( new_x, new_v, out=None)\n",
    "            \n",
    "            compare_min_max.append((image_name_class[0],image_name_class[1],k, max(kdl)))\n",
    "           \n",
    "    #####All_Images.append((image_name_class[0],image_name_class[1],list((len(t_images_btween_0_05),len(t_images_btween_05_1),len(t_images_btween_1_2),len(t_images_grt_2_5), len(t_images_grt_5_10),len(t_images_grt_10)))))\n",
    "    homogeneity_All_Images.append(compare_min_max)\n",
    "homogeneity_source_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_sum_dkls = 0\n",
    "energy_all_nums = []\n",
    "for df in energy_All_Images:\n",
    "    energy_sum_dkls = energy_sum_dkls + df[1][3]\n",
    "    energy_all_nums.append(df[1][3])\n",
    "    #print(df[1][3])\n",
    "energy_average_dkl_v = energy_sum_dkls/ len(energy_All_Images)\n",
    "energy_median_v = statistics.median(energy_all_nums)\n",
    "#get the values below and above the average\n",
    "energy_below_avrg = []\n",
    "energy_above_avrg = []\n",
    "\n",
    "for fg in energy_All_Images:\n",
    "    if fg[1][3] < energy_average_dkl_v:\n",
    "        energy_below_avrg.append(fg[1])\n",
    "    elif fg[1][3] >= energy_average_dkl_v:\n",
    "        energy_above_avrg.append(fg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2044\n"
     ]
    }
   ],
   "source": [
    "print(len(energy_above_avrg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_sum_dkls = 0\n",
    "correlation_all_nums = []\n",
    "for df in correlation_All_Images:\n",
    "    correlation_sum_dkls = correlation_sum_dkls + df[1][3]\n",
    "    correlation_all_nums.append(df[1][3])\n",
    "    #print(df[1][3])\n",
    "correlation_average_dkl_v = correlation_sum_dkls/ len(correlation_All_Images)\n",
    "correlation_median_v = statistics.median(correlation_all_nums)\n",
    "#get the values below and above the average\n",
    "correlation_below_avrg = []\n",
    "correlation_above_avrg = []\n",
    "\n",
    "for fg in correlation_All_Images:\n",
    "    if fg[1][3] < correlation_average_dkl_v:\n",
    "        correlation_below_avrg.append(fg[1])\n",
    "    elif fg[1][3] >= correlation_average_dkl_v:\n",
    "        correlation_above_avrg.append(fg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneity_sum_dkls = 0\n",
    "homogeneity_all_nums = []\n",
    "for df in homogeneity_All_Images:\n",
    "    homogeneity_sum_dkls = homogeneity_sum_dkls + df[1][3]\n",
    "    homogeneity_all_nums.append(df[1][3])\n",
    "    #print(df[1][3])\n",
    "homogeneity_average_dkl_v = homogeneity_sum_dkls/ len(homogeneity_All_Images)\n",
    "homogeneity_median_v = statistics.median(homogeneity_all_nums)\n",
    "#get the values below and above the average\n",
    "homogeneity_below_avrg = []\n",
    "homogeneity_above_avrg = []\n",
    "\n",
    "for fg in homogeneity_All_Images:\n",
    "    if fg[1][3] < homogeneity_average_dkl_v:\n",
    "        homogeneity_below_avrg.append(fg[1])\n",
    "    elif fg[1][3] >= homogeneity_average_dkl_v:\n",
    "        homogeneity_above_avrg.append(fg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "energy_above_other = []\n",
    "for w in energy_above_avrg:\n",
    "    image_n = w[1]+\"/\"+w[0]\n",
    "    image_c = w[1]\n",
    "    \n",
    "    energy_above_other.append((image_n,image_c))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_above_other = []\n",
    "for w in correlation_above_avrg:\n",
    "    image_n = w[1]+\"/\"+w[0]\n",
    "    image_c = w[1]\n",
    "    \n",
    "    correlation_above_other.append((image_n,image_c))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2146\n"
     ]
    }
   ],
   "source": [
    "print(len(correlation_above_avrg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneity_above_other = []\n",
    "for w in homogeneity_above_avrg:\n",
    "    image_n = w[1]+\"/\"+w[0]\n",
    "    image_c = w[1]\n",
    "    \n",
    "    homogeneity_above_other.append((image_n,image_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('measures/DKL/DenseNet169/mnist_test_energy_above_glcm_above.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)  # write the header\n",
    "    writer.writerow([\"file\", \"label\"])\n",
    "    for l_item in energy_above_other:\n",
    "        writer.writerow(l_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('measures/DKL/DenseNet169/mnist_test_correlation_above_glcm_above.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)  # write the header\n",
    "    writer.writerow([\"file\", \"label\"])\n",
    "    for l_item in correlation_above_other:\n",
    "        writer.writerow(l_item)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('measures/DKL/DenseNet169/mnist_test_homogeneity_above_glcm_above.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)  # write the header\n",
    "    writer.writerow([\"file\", \"label\"])\n",
    "    for l_item in homogeneity_above_other:\n",
    "        writer.writerow(l_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "energy_below_other = []\n",
    "for z in energy_below_avrg:\n",
    "    image_n = z[1]+\"/\"+z[0]\n",
    "    image_c = z[1]\n",
    "    energy_below_other.append((image_n,image_c))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_below_other = []\n",
    "for z in correlation_below_avrg:\n",
    "    image_n = z[1]+\"/\"+z[0]\n",
    "    image_c = z[1]\n",
    "    correlation_below_other.append((image_n,image_c))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "homogeneity_below_other = []\n",
    "for z in homogeneity_below_avrg:\n",
    "    image_n = z[1]+\"/\"+z[0]\n",
    "    image_c = z[1]\n",
    "    homogeneity_below_other.append((image_n,image_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "with open('measures/DKL/DenseNet169/mnist_test_energy_above_glcm_below.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)  # write the header\n",
    "    writer.writerow([\"file\", \"label\"])\n",
    "    for l_item in energy_below_other:\n",
    "        writer.writerow(l_item)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('measures/DKL/DenseNet169/mnist_test_correlation_above_glcm_below.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)  # write the header\n",
    "    writer.writerow([\"file\", \"label\"])\n",
    "    for l_item in correlation_below_other:\n",
    "        writer.writerow(l_item)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "\n",
    "with open('measures/DKL/DenseNet169/mnist_test_homogeneity_above_glcm_below.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)  # write the header\n",
    "    writer.writerow([\"file\", \"label\"])\n",
    "    for l_item in homogeneity_below_other:\n",
    "        writer.writerow(l_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
