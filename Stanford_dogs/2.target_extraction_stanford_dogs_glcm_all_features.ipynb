{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.9 MB 19.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.19.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 48.3 MB 18.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from opencv-python-headless) (1.19.5)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.6.0.66\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.17.2-cp36-cp36m-manylinux1_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 19.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.3.3)\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.5.4)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2020.9.3-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 90.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (8.1.0)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 82.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.0\n",
      "  Downloading networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 73.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "Installing collected packages: tifffile, PyWavelets, networkx, scikit-image\n",
      "Successfully installed PyWavelets-1.1.1 networkx-2.5.1 scikit-image-0.17.2 tifffile-2020.9.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16 as vgg16\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as mobilenetv2\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 as resnet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 as inception\n",
    "from tensorflow.keras.applications.densenet import DenseNet169 as densenet\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import Model\n",
    "from keras import layers, Sequential\n",
    "from matplotlib import pyplot\n",
    "from math import floor\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from numpy import expand_dims, array, exp, max\n",
    "import json\n",
    "import skimage.feature as feature\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 1s 0us/step\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 149, 149, 32)      864       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "=================================================================\n",
      "Total params: 864\n",
      "Trainable params: 864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = inception()\n",
    "model2 = Model(inputs=model1.inputs, outputs=model1.layers[1].output)\n",
    "# model.add(layers.MaxPool2D(pool_size=(2, 2),strides=(1, 1), padding='valid'))\n",
    "model = Sequential(layers=model2.layers)\n",
    "model.add(layers.MaxPool2D(pool_size=(3, 3), strides=(3, 3), padding='same'))\n",
    "# model = Model(inputs=model.inputs, outputs = model.layers[1].output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns:\n",
    "  def __init__(self, numPoints, radius):\n",
    "    self.numPoints = numPoints\n",
    "    self.radius = radius\n",
    "\n",
    "  def describe(self, image, eps = 1e-7):\n",
    "    lbp = feature.local_binary_pattern(image, self.numPoints, self.radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, self.numPoints+3), range=(0, self.numPoints + 2))\n",
    "\n",
    "    # Normalize the histogram\n",
    "    hist = hist.astype('float')\n",
    "    hist /= (hist.sum() + eps)\n",
    "\n",
    "    return hist, lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n02089973_3156.jpg', 'n02089973_3159.jpg', 'n02089973_1352.jpg', 'n02089973_1232.jpg', 'n02089973_3265.jpg', 'n02089973_32.jpg', 'n02089973_3480.jpg', 'n02089973_437.jpg', 'n02089973_3119.jpg', 'n02089973_1324.jpg', 'n02089973_1877.jpg', 'n02089973_2781.jpg', 'n02089973_2300.jpg', 'n02089973_2045.jpg', 'n02089973_1623.jpg', 'n02089973_2603.jpg', 'n02089973_2.jpg', 'n02089973_957.jpg', 'n02089973_981.jpg', 'n02089973_2681.jpg', 'n02089973_770.jpg', 'n02089973_1690.jpg', 'n02089973_2509.jpg', 'n02089973_2476.jpg', 'n02089973_1260.jpg', 'n02089973_3401.jpg', 'n02089973_1345.jpg', 'n02089973_2181.jpg', 'n02089973_382.jpg', 'n02089973_1907.jpg', 'n02089973_1277.jpg', 'n02089973_4307.jpg', 'n02089973_2551.jpg', 'n02089973_3651.jpg', 'n02089973_1078.jpg', 'n02089973_2599.jpg', 'n02089973_1255.jpg', 'n02089973_569.jpg', 'n02089973_1803.jpg', 'n02089973_2500.jpg', 'n02089973_1381.jpg', 'n02089973_417.jpg', 'n02089973_2093.jpg', 'n02089973_3323.jpg', 'n02089973_1357.jpg', 'n02089973_811.jpg', 'n02089973_1701.jpg', 'n02089973_3037.jpg', 'n02089973_3454.jpg', 'n02089973_1458.jpg', 'n02089973_973.jpg', 'n02089973_140.jpg', 'n02089973_2457.jpg', 'n02089973_1957.jpg', 'n02089973_612.jpg', 'n02089973_1312.jpg', 'n02089973_533.jpg', 'n02089973_2068.jpg', 'n02089973_1132.jpg', 'n02089973_1490.jpg', 'n02089973_3113.jpg', 'n02089973_3074.jpg', 'n02089973_2716.jpg', 'n02089973_2397.jpg', 'n02089973_2150.jpg', 'n02089973_2322.jpg', 'n02089973_251.jpg', 'n02089973_1748.jpg', 'n02089973_3426.jpg', 'n02089973_1303.jpg', 'n02089973_1516.jpg', 'n02089973_4185.jpg', 'n02089973_243.jpg', 'n02089973_2756.jpg', 'n02089973_556.jpg', 'n02089973_3820.jpg', 'n02089973_3604.jpg', 'n02089973_3420.jpg', 'n02089973_843.jpg', 'n02089973_504.jpg', 'n02089973_2345.jpg', 'n02089973_3147.jpg', 'n02089973_2943.jpg', 'n02089973_4084.jpg', 'n02089973_2810.jpg', 'n02089973_3040.jpg', 'n02089973_208.jpg', 'n02089973_2249.jpg', 'n02089973_97.jpg', 'n02089973_2331.jpg', 'n02089973_48.jpg', 'n02089973_3307.jpg', 'n02089973_1249.jpg', 'n02089973_3671.jpg', 'n02089973_2211.jpg', 'n02089973_2064.jpg', 'n02089973_263.jpg', 'n02089973_1799.jpg', 'n02089973_1841.jpg', 'n02089973_3055.jpg', 'n02089973_2484.jpg', 'n02089973_186.jpg', 'n02089973_2905.jpg', 'n02089973_270.jpg', 'n02089973_846.jpg', 'n02089973_2404.jpg', 'n02089973_809.jpg', 'n02089973_2054.jpg', 'n02089973_2415.jpg', 'n02089973_2133.jpg', 'n02089973_3299.jpg', 'n02089973_4010.jpg', 'n02089973_2608.jpg', 'n02089973_1375.jpg', 'n02089973_3799.jpg', 'n02089973_3726.jpg', 'n02089973_1106.jpg', 'n02089973_3860.jpg', 'n02089973_1492.jpg', 'n02089973_1733.jpg', 'n02089973_1066.jpg', 'n02089973_3982.jpg', 'n02089973_319.jpg', 'n02089973_1888.jpg', 'n02089973_99.jpg', 'n02089973_3120.jpg', 'n02089973_1890.jpg', 'n02089973_2308.jpg', 'n02089973_3160.jpg', 'n02089973_1076.jpg', 'n02089973_529.jpg', 'n02089973_2791.jpg', 'n02089973_255.jpg', 'n02089973_1000.jpg', 'n02089973_289.jpg', 'n02089973_3933.jpg', 'n02089973_3433.jpg', 'n02089973_2073.jpg', 'n02089973_4055.jpg', 'n02089973_4359.jpg', 'n02089973_1577.jpg', 'n02089973_525.jpg', 'n02089973_2497.jpg', 'n02089973_2110.jpg', 'n02089973_3136.jpg', 'n02089973_1030.jpg', 'n02089973_1.jpg', 'n02089973_888.jpg', 'n02089973_1298.jpg', 'n02089973_3647.jpg', 'n02089973_2633.jpg', 'n02089973_1763.jpg', 'n02089973_3688.jpg', 'n02089973_3089.jpg', 'n02089973_1356.jpg', 'n02089973_2017.jpg', 'n02089973_3243.jpg']\n"
     ]
    }
   ],
   "source": [
    "###########################THIS CODE CHECKS IMAGES FROM A FOLDER#################################\n",
    "\n",
    "def sortTrainImages():\n",
    "    # get the class labels from training datasets\n",
    "    p = {}\n",
    "    data_path = '../../../paper3/StanfordDogs/Stanford_Dogs'\n",
    "    img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255, rotation_range=20)\n",
    "    #labels = img_gen.flow_from_directory(data_path + '/Images')\n",
    "    #train_labels = labels.class_indices.keys()\n",
    "\n",
    "    #for lbl in train_labels:\n",
    "    resnet_path = data_path +'/Images/' + 'n02089973-English_foxhound'\n",
    "    p_files = [f for f in listdir(resnet_path) if isfile(join(resnet_path, f))]\n",
    "    pests_images = np.empty(len(p_files), dtype=object)\n",
    "    print(p_files)\n",
    "    for m in range(0, len(p_files)):\n",
    "        \n",
    "            #print(join(resnet_path, p_files[m]))\n",
    "        imageName_x = p_files[m]\n",
    "        p.update({'n02089973-English_foxhound' + \"_\" + str(m): imageName_x})\n",
    "            ######if m < 25:\n",
    "                #pests_images[m] = cv2.imread(join(resnet_path, p_files[m]))\n",
    "                # get the name of the image\n",
    "                ######imageName_x = p_files[m]\n",
    "                #####p.update({lbl + \"_\" + str(m): imageName_x})\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "images_collection = sortTrainImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softMax(temperature, features_list):\n",
    "    feat_list = [x / temperature for x in features_list]\n",
    "    feature_list = exp(feat_list - max(feat_list))\n",
    "    return feature_list / feature_list.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img:\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 299, 299, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 224, 224, 3).\n",
      "img:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n",
      "img:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAENklEQVR4nO3cwW3jMABFQXGREpxz2H8tdhE5Jz1wG4gBO5D3CdqZMyEQ+MA78KCx1toA+Pf+1BcA+F8JMEBEgAEiAgwQEWCAiAADRN6eOXy5XNac80VX4VG32+17rfW+1/fsegx2Pa972z4V4Dnndr1e97sVvzLG+Nzze3Y9Brue171tPUEARAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQEWCAiAADRAQYICLAABEBBogIMEBEgAEiY631+OExvrZt+3zddXjQx1rrfa+P2fUw7HpeP277VIAB2I8nCICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBgg8vbM4cvlsuacL7oKj7rdbt97/rTFrsdg1/O6t+1TAZ5zbtfrdb9b8StjjF3/cGXXY7Dred3b1hMEQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggIsAAEQEGiAgwQESAASICDBARYICIAANEBBggMtZajx8e42vbts/XXYcHfay13vf6mF0Pw67n9eO2TwUYgP14ggCICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBA5O2Zw5fLZc05X3QVHnW73b73/GeAXY/Brud1b9unAjzn3K7X63634lfGGLv+YMWux2DX87q3rScIgIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBARIABIgIMEBFggIgAA0QEGCAiwAARAQaICDBAZKy1Hj88xte2bZ+vuw4P+lhrve/1Mbsehl3P68dtnwowAPvxBAEQEWCAiAADRAQYICLAABEBBogIMEBEgAEiAgwQ+QtCyayvdbrBBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_prob_dist_array = []\n",
    "\n",
    "for o, j in images_collection.items():\n",
    "    print(\"img:\")\n",
    "    contrast_features_array = []\n",
    "    homogeneity_features_array = []\n",
    "    dissimilarity_features_array = []\n",
    "    energy_features_array = []\n",
    "    correlation_features_array = []\n",
    "    \n",
    "    image_string = '../../../paper3/StanfordDogs/Stanford_Dogs/Images/n02089973-English_foxhound/' + j\n",
    "  \n",
    "    img = imread(image_string)\n",
    "    img = resize(img,(224,224,3))\n",
    "        # get the path of image to extract the class\n",
    "    img_class =j[0]\n",
    "    img = img_to_array(img)    \n",
    "    # expand the image dimensions\n",
    "    img = expand_dims(img, axis=0)\n",
    "        # scale the pixels\n",
    "    img = preprocess_input(img)\n",
    "        # get the features of the first layer\n",
    "    feature_maps = model.predict(img)\n",
    "    \n",
    "    correlation_numerator = []\n",
    "    energy_numerator = []\n",
    "    homogeneity_numerator = []\n",
    "    dissimilarity_numerator = []\n",
    "    contrast_numerator = []\n",
    "    \n",
    "    ix = 1\n",
    "    square = 3\n",
    "\n",
    "    for _ in range(square):\n",
    "        for _ in range(square):\n",
    "            ax = pyplot.subplot(square, square, ix)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ##################FLATTEN THE FEATURE for dimensionality reduction##################################\n",
    "            feature_items = array(feature_maps[0, :, :, ix - 1])\n",
    "            #get the unsigned values of the feature\n",
    "            features_x = feature_items.astype(np.uint8)        \n",
    "            #get the grey-level cooccurrence matrix\n",
    "            graycom = feature.greycomatrix(features_x, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256)            \n",
    "            # Find the GLCM properties\n",
    "            correlation = feature.greycoprops(graycom, 'correlation') \n",
    "            contrast = feature.greycoprops(graycom, 'contrast')\n",
    "            dissimilarity = feature.greycoprops(graycom, 'dissimilarity')\n",
    "            homogeneity = feature.greycoprops(graycom, 'homogeneity')\n",
    "            energy = feature.greycoprops(graycom, 'energy')\n",
    "            correlation = feature.greycoprops(graycom, 'correlation') \n",
    "            \n",
    "            #get the probability distribution using correlation harrick features except correlation\n",
    "            contrast_prob = softMax(0.5,contrast[0])\n",
    "            dissimilarity_prob = softMax(0.5,dissimilarity[0])\n",
    "            homogeneity_prob = softMax(0.5,homogeneity[0])\n",
    "            energy_prob = softMax(0.5,energy[0])\n",
    "            correlation_prob = softMax(0.5,correlation[0])\n",
    "            \n",
    "            #get the conflated distribution for this feature\n",
    "            conf_numerator_contrast = np.prod(contrast_prob)\n",
    "            conf_numerator_dissimilarity = np.prod(correlation_prob)\n",
    "            conf_numerator_homogeneity = np.prod(homogeneity_prob)\n",
    "            conf_numerator_energy = np.prod(energy_prob)\n",
    "            conf_numerator_correlation = np.prod(correlation_prob)\n",
    "            \n",
    "            contrast_numerator.append(conf_numerator_contrast)\n",
    "            energy_numerator.append(conf_numerator_energy)\n",
    "            dissimilarity_numerator.append(conf_numerator_dissimilarity)\n",
    "            homogeneity_numerator.append(conf_numerator_homogeneity)\n",
    "            correlation_numerator.append(conf_numerator_correlation)\n",
    "            \n",
    "            #image_features_array.append(correlation_prob)\n",
    "            contrast_features_array.append(contrast_numerator)\n",
    "            homogeneity_features_array.append(homogeneity_numerator)\n",
    "            dissimilarity_features_array.append(dissimilarity_numerator)\n",
    "            energy_features_array.append(energy_numerator)\n",
    "            correlation_features_array.append(correlation_numerator)\n",
    "            #pyplot.imshow(feature_maps[0, :, :, ix - 1], cmap='gray')\n",
    "            \n",
    "            ix += 1\n",
    "    correlation_denominator = np.trapz(correlation_numerator,axis=0)\n",
    "    contrast_denominator = np.trapz(contrast_numerator,axis=0)\n",
    "    homogeneity_denominator = np.trapz(homogeneity_numerator,axis=0)\n",
    "    dissimilarity_denominator = np.trapz(dissimilarity_numerator,axis=0)\n",
    "    energy_denominator = np.trapz(energy_numerator,axis=0)\n",
    "    \n",
    "    #conflated distribution for the image becomes\n",
    "    conflated_dist_correlation = correlation_numerator/correlation_denominator\n",
    "    conflated_dist_contrast = contrast_numerator/contrast_denominator\n",
    "    conflated_dist_homogeneity = homogeneity_numerator/homogeneity_denominator\n",
    "    conflated_dist_dissimilarity = dissimilarity_numerator/dissimilarity_denominator\n",
    "    conflated_dist_energy = energy_numerator/energy_denominator\n",
    "    \n",
    "    new_rec_corr = {j + \"_/\" +'n02089973-English_foxhound': conflated_dist_correlation.tolist()}\n",
    "    new_rec_cont = {j + \"_/\" +'n02089973-English_foxhound': conflated_dist_contrast.tolist()}\n",
    "    new_rec_homo = {j + \"_/\" +'n02089973-English_foxhound': conflated_dist_homogeneity.tolist()}\n",
    "    new_rec_diss = {j + \"_/\" +'n02089973-English_foxhound': conflated_dist_dissimilarity.tolist()}\n",
    "    new_rec_ener = {j + \"_/\" +'n02089973-English_foxhound': conflated_dist_energy.tolist()}\n",
    "        \n",
    "    with open(\"InceptionV3/glcm/stanford_domain_data_new_correlation_glcm.json\", 'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        # Join new_data with file_data inside emp_details\n",
    "        file_data[\"target_images\"].append(new_rec_corr)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file, indent=4)\n",
    "    \n",
    "    with open(\"InceptionV3/glcm/stanford_domain_data_new_contrast_glcm.json\", 'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        # Join new_data with file_data inside emp_details\n",
    "        file_data[\"target_images\"].append(new_rec_cont)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file, indent=4)\n",
    "    \n",
    "    with open(\"InceptionV3/glcm/stanford_domain_data_new_homogeneity_glcm.json\", 'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        # Join new_data with file_data inside emp_details\n",
    "        file_data[\"target_images\"].append(new_rec_homo)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file, indent=4)\n",
    "        \n",
    "    with open(\"InceptionV3/glcm/stanford_domain_data_new_dissimilarity_glcm.json\", 'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        # Join new_data with file_data inside emp_details\n",
    "        file_data[\"target_images\"].append(new_rec_diss)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file, indent=4)\n",
    "        \n",
    "    with open(\"InceptionV3/glcm/stanford_domain_data_new_energy_glcm.json\", 'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        # Join new_data with file_data inside emp_details\n",
    "        file_data[\"target_images\"].append(new_rec_ener)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file, indent=4)\n",
    "\n",
    "    ##if they need to be saved in a bigger file\n",
    "    #features_prob_dist_array.append(conflated_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
