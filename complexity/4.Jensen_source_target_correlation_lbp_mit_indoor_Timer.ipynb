{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.5.4)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dictances in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
      "Requirement already satisfied: support-developer in /usr/local/lib/python3.6/dist-packages (from dictances) (1.0.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dictances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import json\n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "from numpy import expand_dims, array, exp, max\n",
    "import scipy\n",
    "from scipy.special import rel_entr\n",
    "import csv\n",
    "import statistics\n",
    "from numpy import expand_dims, array, exp, max\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import wasserstein_distance\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import sklearn\n",
    "from tensorflow import keras\n",
    "import string\n",
    "from scipy.special import rel_entr\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 as resnet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 as vgg16\n",
    "from tensorflow.keras.applications.densenet import DenseNet169 as densenet\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 as inceptionv3\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB1 as efficient\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as mobilenetv2\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet as mobilenet\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import combinations\n",
    "import csv\n",
    "# import the timeit module\n",
    "import timeit\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "from dictances import bhattacharyya, bhattacharyya_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the timeit module\n",
    "import timeit\n",
    "import math\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hellinger_fast(p, q):\n",
    "    \"\"\"Hellinger distance between two discrete distributions.\n",
    "       In pure Python.\n",
    "       Fastest version.\n",
    "    \"\"\"\n",
    "    return sum([ (math.sqrt(p_i) - math.sqrt(q_i))**2 for p_i, q_i in zip(p,q) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to suppress division errors\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "new_final_source_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening final JSON files\n",
    "contrast_source_data = open('../paper3/files/glcm/source_domain_data_new_energy_glcm.json')\n",
    "\n",
    "#for target data\n",
    "contrast_target_data = open('files/Caltech256/DenseNet169/glcm/caltech_domain_data_new_energy_glcm.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns JSON object\n",
    "contrast_source_data_d = json.load(contrast_source_data)\n",
    "\n",
    "contrast_target_data_d = json.load(contrast_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kdl dictionary\n",
    "kdl_dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL(p, q):\n",
    "    a = []\n",
    "    b = []\n",
    "    for k in p:\n",
    "        a.append(Decimal(k))\n",
    "\n",
    "    for l in q:\n",
    "        b.append(Decimal(l))\n",
    "\n",
    "    a = np.asarray(a, dtype=np.float64)\n",
    "    b = np.asarray(b, dtype=np.float64)\n",
    "\n",
    "    return np.sum(np.where(((a != 0) & (b != 0)), a * np.log(a / b), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softMax(temperature, features_list):\n",
    "    feat_list = [x / temperature for x in features_list]\n",
    "    feature_list = exp(feat_list - max(feat_list))\n",
    "    return feature_list / feature_list.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data for the contrast target image\n",
    "contrast_target_data_array = []\n",
    "for p in range(0, len(contrast_target_data_d['target_images'])):\n",
    "    for i, j in contrast_target_data_d['target_images'][p].items():\n",
    "        contrast_target_data_array.append((i,np.array(j)))\n",
    "contrast_target_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7710\n"
     ]
    }
   ],
   "source": [
    "print(len(contrast_target_data_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KDL -selected points execution time:- 4.678331363014877\n",
      "used memory 12278\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jensen execution time:- 74.26523017702857\n",
      "used memory 775056\n"
     ]
    }
   ],
   "source": [
    "###contrast comparison code\n",
    "contrast_All_Images = []\n",
    "contrast_average_dkl = []\n",
    "\n",
    "#check the timer_start\n",
    "start_hellinger = timeit.default_timer()\n",
    "#check memory consumption\n",
    "# starting the monitoring\n",
    "tracemalloc.start()\n",
    "\n",
    "for x in contrast_target_data_array[:1]:\n",
    "#for x in target_data_array:\n",
    "    t_images_btween_0_05 = []\n",
    "    t_images_btween_05_1 = []\n",
    "    t_images_btween_1_2 = []\n",
    "    t_images_grt_2_5 = []\n",
    "    t_images_grt_5_10 = []\n",
    "    t_images_grt_10 = []\n",
    "    \n",
    "    image_name_class =  x[0].split('_/') #name[0]; class[1]\n",
    "    compare_min_max = []\n",
    "    \n",
    "    \n",
    "            \n",
    "    # get the data for the source images\n",
    "    for m in range(0, len(contrast_source_data_d['source_images'])):\n",
    "        #print(\"source\",source_data_d['source_images'][m][0])\n",
    "        for k, v in contrast_source_data_d['source_images'][m].items():\n",
    "            # compare the value of v with that of the target image\n",
    "            # if 'caterpillar' in k.lower():\n",
    "            # remove the zeros from the list\n",
    "            new_v = np.array(v).flatten()\n",
    "            #get the top items in x\n",
    "            items = np.sort(x[1])\n",
    "            item_size = items[-len(new_v):]\n",
    "            new_x = item_size.flatten()\n",
    "            \n",
    "            new_d = softMax(0.5, new_x)     \n",
    "            new_y = softMax(0.5, new_v)\n",
    "            \n",
    "            kdl = rel_entr( new_x, new_v, out=None)\n",
    "            new_bhattacharyya = bhattacharyya(dict(enumerate(new_x.flatten(), 1)),dict(enumerate(new_v.flatten(), 1)) )\n",
    "            new_wasserstein = wasserstein_distance(new_x,new_v)\n",
    "            new_jensen = distance.jensenshannon(new_x,new_v)\n",
    "            new_hellinger = hellinger_fast(new_x,new_v)\n",
    "            \n",
    "            compare_min_max.append((image_name_class[0],image_name_class[1],k, max(new_bhattacharyya)))\n",
    "            \n",
    "contrast_All_Images.append(compare_min_max)\n",
    "    \n",
    "contrast_source_data.close()\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "execution_time = stop - start_hellinger\n",
    "print(\"KDL -selected points execution time:-\", execution_time)\n",
    "\n",
    "# displaying the memory\n",
    "print(\"used memory\",tracemalloc.get_traced_memory()[1]-tracemalloc.get_traced_memory()[0])\n",
    " \n",
    "# stopping the library\n",
    "tracemalloc.stop()\n",
    "\n",
    "model_name = densenet\n",
    "input_t = keras.Input(shape=(224, 224, 3))\n",
    "model = model_name(include_top=False,\n",
    "                   weights=\"imagenet\",\n",
    "                   input_tensor=input_t)\n",
    "\n",
    "\n",
    "# get the layer index\n",
    "def getLayerIndex(model_i, layer_name):\n",
    "    for pos, layer_g in enumerate(model_i.layers):\n",
    "        if layer_g.name == layer_name:\n",
    "            return pos\n",
    "\n",
    "\n",
    "# get the convolved layers into an array for looping\n",
    "convolved_layers = []\n",
    "convolved_layer_names = []\n",
    "# create a list to place them\n",
    "layer_cosine_list = []\n",
    "layer_final_cos_list = []\n",
    "\n",
    "for layer in model.layers[0:-2]:\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "\n",
    "    index = getLayerIndex(model, layer.name)\n",
    "    #print(layer.name)\n",
    "    # append the convolved layer\n",
    "    convolved_layers.append(index)\n",
    "    convolved_layer_names.append(layer)\n",
    "\n",
    "jdk = {}\n",
    "for lyr in convolved_layer_names:\n",
    "    ary = np.array(lyr.get_weights(), dtype=object)\n",
    "    layer_index = getLayerIndex(model, lyr.name)\n",
    "    if len(ary) != 0:\n",
    "        # filters, biases = layer.get_weights()\n",
    "        # print(filters.shape)\n",
    "        ary = np.array(lyr.get_weights(), dtype=object)\n",
    "\n",
    "        zipper_dict = {}\n",
    "        dict_array = []\n",
    "\n",
    "        # check for the arrays\n",
    "        for x in ary:\n",
    "            # print(len(x))\n",
    "            # find if the array is 1 dim\n",
    "            if x.ndim > 1:\n",
    "                for y in x:\n",
    "                    for z in y:\n",
    "                        u = 0\n",
    "                        for za in z:\n",
    "                            # get all the positive elements in this and push them into an array\n",
    "                            positive_elements = []\n",
    "                            for pos_item in za:\n",
    "                                if pos_item > 0:\n",
    "                                    positive_elements.append(pos_item)\n",
    "                            u = u + 1\n",
    "                            zipper_dict.update({u: positive_elements})\n",
    "\n",
    "            elif x.ndim == 1:\n",
    "                # get the items/arrays with more than the 1 dimension\n",
    "                print(\"\")\n",
    "        # print(\"lyr:\",lyr.name)\n",
    "        # get two items per tuple\n",
    "        for i in range(1, len(zipper_dict), 2):\n",
    "            if len(zipper_dict[i]) > 0:\n",
    "                if len(zipper_dict[i]) == len(zipper_dict[i + 1]):\n",
    "\n",
    "                    new_i = np.array(zipper_dict[i]).reshape(1, -1)\n",
    "                    new_i_plus_1 = np.array(zipper_dict[i + 1]).reshape(1, -1)\n",
    "                    cos_item = np.ravel(cosine_similarity(new_i, new_i_plus_1))\n",
    "                    layer_cosine_list.append(cos_item)\n",
    "\n",
    "                elif len(zipper_dict[i]) > len(zipper_dict[i + 1]):\n",
    "\n",
    "                    diff_len = len(np.array(zipper_dict[i])) - len(np.array(zipper_dict[i + 1]))\n",
    "                    old_i = np.pad(zipper_dict[i + 1], (0, diff_len), 'constant')\n",
    "\n",
    "                    new_i = old_i.reshape(1, -1)\n",
    "                    new_i_plus_1 = np.array(zipper_dict[i]).reshape(1, -1)\n",
    "\n",
    "                    cos_item = np.ravel(cosine_similarity(new_i, new_i_plus_1))\n",
    "                    layer_cosine_list.append(cos_item)\n",
    "\n",
    "                elif len(zipper_dict[i]) < len(zipper_dict[i + 1]):\n",
    "                    # print(\"######less than i plus 1#########\")\n",
    "\n",
    "                    diff_len = len(zipper_dict[i + 1]) - len(zipper_dict[i])\n",
    "                    old_i = np.pad(zipper_dict[i], (0, diff_len), 'constant')\n",
    "                    new_i = old_i.reshape(1, -1)\n",
    "                    new_i_plus_1 = np.array(zipper_dict[i + 1]).reshape(1, -1)\n",
    "\n",
    "                    cos_item = np.ravel(cosine_similarity(new_i, new_i_plus_1))\n",
    "                    layer_cosine_list.append(cos_item)\n",
    "\n",
    "\n",
    "        # calculate softmax function\n",
    "        def softmax(s_et):\n",
    "            e_set = np.exp(s_et - np.max(s_et))\n",
    "            return e_set / e_set.sum(axis=0)\n",
    "\n",
    "\n",
    "        for a in layer_cosine_list:\n",
    "            layer_final_cos_list.append(a)\n",
    "        # print(layer_final_cos_list)\n",
    "        layer_softmax_values = softmax(np.ravel(np.array(layer_cosine_list, dtype=np.float32).reshape(1, -1)))\n",
    "        jdk.update({layer_index: layer_softmax_values})\n",
    "\n",
    "# jdk gives a dictionary made up of probability distributions\n",
    "# print(jdk)\n",
    "# print(\"the other one is\")\n",
    "b = [x for y, x in enumerate(jdk) if y != i]\n",
    "all_items = list(combinations(b, 2))\n",
    "\n",
    "# put the layers in a dictionary and rank them --JENSEN\n",
    "other = []\n",
    "#check timer here\n",
    "# start the timer\n",
    "start_jensen = timeit.default_timer()\n",
    "#check memory consumption\n",
    "# starting the monitoring\n",
    "tracemalloc.start()\n",
    "\n",
    "       \n",
    "for a in all_items:\n",
    "    if len(jdk[a[0]]) > len(jdk[a[1]]):\n",
    "        \n",
    "        dif_1 = len(np.array(jdk[a[0]])) - len(np.array(jdk[a[1]]))\n",
    "        new_jdk = np.pad(np.array(jdk[a[1]]), (0, dif_1), 'constant').reshape(1, -1)\n",
    "        new_i_jdk = np.array(jdk[a[0]]).reshape(1, -1)\n",
    "        #print(\"########################other###############\") \n",
    "        new_jensen = distance.jensenshannon(new_jdk[0],new_i_jdk[0])\n",
    "        ##print(new_jensen)\n",
    "        #print(\"##########################end other#########\")\n",
    "        \n",
    "        #hellinger_fast(new_i_jdk, new_jdk)\n",
    "        ##kl_pq = rel_entr(np.ravel(np.ravel(new_i_jdk), new_jdk))\n",
    "       # print(\"layer:\", a[0], \" and layer: \", a[1], ':KL(P ||2 Q): %.3f nats1' % sum(kl_pq))\n",
    "        ##########m_no = [a[0], a[1], hellinger_fast]\n",
    "        ##########other.append(m_no)\n",
    "\n",
    "    elif len(jdk[a[0]]) < len(jdk[a[1]]):\n",
    "        #check timer here\n",
    "        dif_1 = len(np.array(jdk[a[1]])) - len(np.array(jdk[a[0]]))\n",
    "        new_jdk = np.pad(np.array(jdk[a[0]]), (0, dif_1), 'constant').reshape(1, -1)\n",
    "        new_i_jdk = np.array(jdk[a[1]]).reshape(1, -1)\n",
    "        #print(\"########################other###############\")        \n",
    "        new_jensen = distance.jensenshannon(new_jdk[0],new_i_jdk[0])\n",
    "        \n",
    "        ##print(new_jensen)\n",
    "        #print(\"##########################end other#########\")       \n",
    "        \n",
    "\n",
    "        #kl_pq = rel_entr(np.ravel(new_jdk), np.ravel(new_i_jdk))\n",
    "        #print(\"layer:\", a[0], \" and layer: \", a[1], ':KL(P ||2 Q): %.3f nats' % sum(kl_pq))\n",
    "        #m_no = [a[0], a[1], sum(kl_pq)]\n",
    "        ###########hellinger_fast(new_i_jdk, new_jdk)\n",
    "        ##kl_pq = rel_entr(np.ravel(np.ravel(new_i_jdk), new_jdk))\n",
    "       # print(\"layer:\", a[0], \" and layer: \", a[1], ':KL(P ||2 Q): %.3f nats1' % sum(kl_pq))\n",
    "        ###########m_no = [a[0], a[1], hellinger_fast]\n",
    "        ##############other.append(m_no)\n",
    "stop_jensen = timeit.default_timer()\n",
    "execution_time = stop_jensen - start_jensen\n",
    "print(\"Jensen execution time:-\", execution_time)\n",
    "\n",
    "# displaying the memory\n",
    "print(\"used memory\",tracemalloc.get_traced_memory()[1]-tracemalloc.get_traced_memory()[0])\n",
    " \n",
    "# stopping the library\n",
    "tracemalloc.stop()\n",
    "# with open('mobilenet_kullback_positive.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "#     writer = csv.writer(f)  # write the header\n",
    "#     writer.writerow([\"Layer1\", \"Layer2\", \"DKL\"])\n",
    "#     for l_item in other:\n",
    "#         writer.writerow(l_item)\n",
    "    # All the program statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
